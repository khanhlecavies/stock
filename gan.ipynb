{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 1ms/step\n",
      "Epoch 0, Discriminator Loss: 0.784792959690094, GAN Loss: 0.7300112247467041\n",
      "64/64 [==============================] - 0s 2ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 2ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "Epoch 10, Discriminator Loss: 0.6733156442642212, GAN Loss: 0.7125898599624634\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "Epoch 20, Discriminator Loss: 0.6321983337402344, GAN Loss: 0.7453367114067078\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 2ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 2ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "Epoch 30, Discriminator Loss: 0.6091620922088623, GAN Loss: 0.7623714208602905\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 2ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "Epoch 40, Discriminator Loss: 0.6027166843414307, GAN Loss: 0.7629972696304321\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 3ms/step\n",
      "64/64 [==============================] - 0s 2ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "Epoch 50, Discriminator Loss: 0.6293774843215942, GAN Loss: 0.7417528629302979\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 2ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "Epoch 60, Discriminator Loss: 0.6489123702049255, GAN Loss: 0.7218083143234253\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "Epoch 70, Discriminator Loss: 0.6861530542373657, GAN Loss: 0.7092825770378113\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 2ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 2ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "Epoch 80, Discriminator Loss: 0.7167764902114868, GAN Loss: 0.7414306402206421\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "Epoch 90, Discriminator Loss: 0.744982898235321, GAN Loss: 0.7862603068351746\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "Epoch 100, Discriminator Loss: 0.7539182901382446, GAN Loss: 0.8090668320655823\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "Epoch 110, Discriminator Loss: 0.7444296479225159, GAN Loss: 0.8455312848091125\n",
      "64/64 [==============================] - 0s 2ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "Epoch 120, Discriminator Loss: 0.748866856098175, GAN Loss: 0.8427824974060059\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "Epoch 130, Discriminator Loss: 0.7325190305709839, GAN Loss: 0.8434771299362183\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "Epoch 140, Discriminator Loss: 0.6902080774307251, GAN Loss: 0.8707507848739624\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 2ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "Epoch 150, Discriminator Loss: 0.6448929309844971, GAN Loss: 0.9357103109359741\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "Epoch 160, Discriminator Loss: 0.624018669128418, GAN Loss: 1.0277538299560547\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 2ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "Epoch 170, Discriminator Loss: 0.6216704845428467, GAN Loss: 1.0944894552230835\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "Epoch 180, Discriminator Loss: 0.6207442283630371, GAN Loss: 1.0877866744995117\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "Epoch 190, Discriminator Loss: 0.581238865852356, GAN Loss: 1.0421204566955566\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "64/64 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Predicted opening prices for the next 10 days (original scale): [-1871.9427    462.00247   750.761    -837.67084   366.36847  -604.03033\n",
      "  1822.9261    381.5888    196.96837  -566.5131 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load JSON data\n",
    "with open('data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract features and target\n",
    "time_series = np.array(data['o'])  # Opening prices\n",
    "n_past = 10  # Length of the input sequence\n",
    "n_future = 10  # Number of days to predict\n",
    "\n",
    "# Initialize the scaler and scale the time series data\n",
    "scaler = MinMaxScaler()\n",
    "scaled_time_series = scaler.fit_transform(time_series.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Prepare training data\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "# Create training data with scaled values\n",
    "for i in range(len(scaled_time_series) - n_past - n_future):\n",
    "    x_train.append(scaled_time_series[i:i + n_past])\n",
    "    y_train.append(scaled_time_series[i + n_past:i + n_past + n_future])\n",
    "\n",
    "x_train = np.array(x_train).reshape(-1, n_past, 1)  # Reshape to 3D\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.3, random_state=42)\n",
    "\n",
    "# Build the GAN model\n",
    "latent_dim = 100\n",
    "\n",
    "# Generator\n",
    "generator = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_dim=latent_dim),\n",
    "    layers.Dense(n_past, activation='relu'),\n",
    "    layers.Reshape((n_past, 1))\n",
    "])\n",
    "\n",
    "# Discriminator\n",
    "discriminator = keras.Sequential([\n",
    "    layers.Flatten(input_shape=(n_past, 1)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile discriminator\n",
    "discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Create GAN\n",
    "discriminator.trainable = False\n",
    "gan_input = layers.Input(shape=(latent_dim,))\n",
    "x = generator(gan_input)\n",
    "gan_output = discriminator(x)\n",
    "gan = keras.Model(gan_input, gan_output)\n",
    "\n",
    "# Compile GAN\n",
    "gan.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Training the GAN\n",
    "batch_size = 2048\n",
    "epochs = 200\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    generated_samples = generator.predict(noise)\n",
    "\n",
    "    real_samples = x_train[np.random.randint(0, x_train.shape[0], batch_size)]\n",
    "    combined_samples = np.concatenate([real_samples, generated_samples])\n",
    "\n",
    "    labels = np.array([1] * batch_size + [0] * batch_size)\n",
    "    discriminator_loss = discriminator.train_on_batch(combined_samples, labels)\n",
    "\n",
    "    gan_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Discriminator Loss: {discriminator_loss[0]}, GAN Loss: {gan_loss}\")\n",
    "\n",
    "# Predict the next 10 days' opening prices with a random noise input\n",
    "noise = np.random.normal(0, 1, (1, latent_dim))  # Random noise for the generator\n",
    "predicted_scaled = generator.predict(noise).flatten()  # Flatten the result for easier reading\n",
    "\n",
    "# Inverse transform to get back original scale\n",
    "predicted_original_scale = scaler.inverse_transform(predicted_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Output the predicted opening prices for the next 10 days\n",
    "print(\"Predicted opening prices for the next 10 days (original scale):\", predicted_original_scale)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
